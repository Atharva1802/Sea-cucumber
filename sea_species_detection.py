# -*- coding: utf-8 -*-
"""sea_species detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GpTpf7pQT8RoAtP2_jWLRcAs1BNfb9FH

###Importing the required
"""

import tensorflow as tf
from keras.utils import np_utils
from matplotlib import pyplot as plt
import numpy as np

import keras

"""###Loading and splitting the data"""

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

print("Training images : {}".format(x_train.shape))
print("Testinging images : {}".format(x_test.shape))

print(x_train[0].shape)

for i in range(332,336):
  plt.subplot(120 + 1 + i)
  img = x_train[i]
  plt.imshow(img)
  plt.show()

"""###Processing the data"""

x_train = x_train.reshape(x_train.shape[0], 32 , 32 , 3)
x_test = x_test.reshape(x_test.shape[0], 32 , 32 , 3)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

x_train /= 225
x_test /= 225
n_classes = 10

print("Shape before one hot encoding : ", y_train.shape)
y_train = np_utils.to_categorical(y_train, n_classes)
y_test = np_utils.to_categorical(y_test, n_classes)
print("Shape after one hot encoding : ", y_train.shape)

"""###Building the model"""

from keras.engine.sequential import Sequential
from keras.models import sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten

model = Sequential()
#covolutional layers
model.add(Conv2D(50,kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))

model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout (0.25))

model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
model.add(MaxPool2D (pool_size=(2,2)))
model.add(Dropout(0.25))

model.add (Flatten())

# hidden layer
model.add (Dense (500, activation='relu'))
model.add(Dropout (0.4))
model.add(Dense(250, activation='relu'))
model.add(Dropout (0.3))
# output layer
model.add (Dense(10, activation='softmax'))

#compiling
model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')

#training the model
model.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test))

"""###predicting"""

classes = range(0,10)

names =[
"airplane",
"automobile",
"bird",
"cat",
"deer",
"dog",
"frog",
"horse",
"ship",
"truck"]

# zip the names and classes to make a dictionary of class labels
class_labels = dict(zip(classes, names))

# generate batch of 9 images to predict
batch = x_test[100:109]
labels = np.argmax(y_test[100:109],axis=-1)

# make predictions
predictions = model.predict(batch, verbose = 1)

print(predictions)

for image in predictions:
  print(np.sum(image))

class_result = np.argmax(predictions,axis=-1)
print(class_result)

"""###Final object detection"""

fig, axs= plt.subplots(3, 3, figsize = (19,6))
fig. subplots_adjust(hspace = 1)
axs = axs.flatten()

for i, img in enumerate(batch):
  for key, value in class_labels.items():
    if class_result[i] == key:
      title ='Prediction: {}\nActual: {}'.format(class_labels[key], class_labels[labels[i]])
      axs[i].set_title(title)
      axs[i].axes.get_xaxis().set_visible(False)
      axs[i].axes.get_yaxis().set_visible(False)

  #plot the image
  axs[i].imshow(img)

#show the plot
plt.show()